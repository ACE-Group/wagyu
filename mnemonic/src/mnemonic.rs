use bitvec::prelude::*;
use byteorder::{ByteOrder, BigEndian as ByteOrder_BigEndian};
use hmac::Hmac;
use rand::Rng;
use rand::rngs::OsRng;
use sha2::{Digest, Sha256, Sha512};
use std::str;
use wagu_model::MnemonicError;

use bitvec::cursor::BigEndian;
use std::fs;
use std::ops::{AddAssign, Div};


const PBKDF2_ROUNDS: usize = 2048;
const PBKDF2_BYTES: usize = 64;

/// Mnemonic word languages
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
#[allow(non_camel_case_types)]
pub enum Language {
    CHINESE_SIMPLIFIED,
    CHINESE_TRADITIONAL,
    ENGLISH,
    FRENCH,
    ITALIAN,
    JAPANESE,
    KOREAN,
    SPANISH,
}

/// Represents a BIP39 Mnemonic
pub struct Mnemonic {
    /// Initial entropy for generating the mnemonic. Must be a multiple of 32 bits.
    pub entropy: Vec<u8>,

    /// Language of mnemnoic words
    pub language: Language,

    /// Mnemonic phrase
    pub phrase: String,
}

impl Mnemonic {
    /// generates a new mnemonic with word_count words
    pub fn new(word_count: u8, language: &Language) -> Result<Self, MnemonicError> {
        let entropy_length: usize = match word_count {
            12 => 16,
            15 => 20,
            18 => 24,
            21 => 28,
            24 => 32,
            wc => return Err(MnemonicError::InvalidWordCount(wc))
        };
        let mut entropy_slice_max = [0u8; 32];
        OsRng.try_fill(&mut entropy_slice_max).expect("Error generating random bytes for entropy");
        let entropy_slice_exact = &entropy_slice_max[0..entropy_length];
        let entropy: Vec<u8> = Vec::from(entropy_slice_exact);

        Ok(Mnemonic::from_entropy(&entropy, language)?)
    }

    /// derives a mnemonic from entropy
    pub fn from_entropy(entropy: &Vec<u8>, language: &Language) -> Result<Self, MnemonicError> {

        // The allowed size of ENT is 128-256 bits.
        let word_count: i32 = match entropy.len() {
            16 => 12,
            20 => 15,
            24 => 18,
            28 => 21,
            32 => 24,
            entropy_len => return Err(MnemonicError::InvalidEntropyLength(entropy_len))
        };

        let word_string = match language {
            Language::ENGLISH => fs::read_to_string("src/languages/english.txt").expect("Error reading file"),
            _ => panic!("Invalid language")
        };
        let word_list: Vec<&str> = word_string.lines().collect();

        // A checksum is generated by taking the first `entropy.len() / 32` bits of its SHA256 hash
        let mut hasher = Sha256::new();
        hasher.input(entropy.as_slice());
        let hash_result = hasher.result();

        let cs = word_count.div(3i32) as usize;
        let checksum_bit_slice: &BitSlice = &hash_result[0].as_bitslice::<BigEndian>()[..cs];
        let mut checksum_bit_vector = BitVec::from_bitslice(checksum_bit_slice);


        // The entropy is converted into a bit vector for easier bit manipulation
        let mut encoding_vec: BitVec<LittleEndian> = BitVec::new();
        entropy.iter().for_each(|byte| {
            let byte_bit_slice = byte.as_bitslice::<LittleEndian>();
            let mut byte_bit_vector = BitVec::from_bitslice(&byte_bit_slice);
            encoding_vec.append(&mut byte_bit_vector);
        });

        // The checksum is appended to the end of the initial entropy
        encoding_vec.append(&mut checksum_bit_vector);

        // Next, these concatenated bits are split into groups of 11 bits,
        // each encoding a number from 0-2047, serving as an index into a wordlist.
        // Finally, we convert these numbers into words and use the joined words as a mnemonic sentence.
        let mut phrase = String::new();
        let mut word_bits: Vec<u8> = Vec::with_capacity(11);
        encoding_vec.iter().for_each(|bit| {
            match bit {
                true => word_bits.push(1),
                false => word_bits.push(0)
            }
            if word_bits.len() == 11 {
//                print!("{:?} ", word_bits);
//                print!("{:?} ", get_u11_index(&word_bits));
//                println!("{:?}", word_list[get_u11_index(&word_bits)]);

                phrase.push_str(&word_list[get_u11_index(&word_bits)]);
                phrase.push(' ');
                word_bits = Vec::new();
            }
        });
        // removes trailing space
        phrase.pop();

        /// Returns wordlist index 0-2047 given bit vector in BigEndian form
        fn get_u11_index(bits: &Vec<u8>) -> usize {
            let mut number = 0u16;
            for x in 0..11 {
                if bits[x] == 1 {
                    let exp = (10 - x) as u32;
                    number.add_assign(2u16.pow(exp));
                }
            }

            number as usize
        }

        Ok(Self {
            entropy: entropy.clone(),
            language: language.clone(),
            phrase,
        })
    }

    /// derives a mnemonic from seed phrase
    pub fn from_phrase(phrase: &str, language: &Language) -> Result<Self, MnemonicError> {
        Ok(Self {
            entropy: Mnemonic::to_entropy(phrase, language)?,
            language: language.clone(),
            phrase: String::from(phrase)
        })
    }

    /// derives entropy from seed phrase
    pub fn to_entropy(phrase: &str, language: &Language) -> Result<Vec<u8>, MnemonicError> {
        let mnemonic: Vec<&str> = phrase.split(" ").collect();
        let entropy_length = match mnemonic.len() {
            12 => 128,
            15 => 160,
            18 => 192,
            21 => 224,
            24 => 256,
            wc => return Err(MnemonicError::InvalidWordCount(wc as u8))
        };


        let mut entropy: BitVec<BigEndian> = BitVec::new();
        mnemonic.iter().for_each(|word| {
            // get index of word in dictionary
            let index = Mnemonic::get_wordlist_index(word, language).map_err( |err| {
                return err
            });

            // turn u11 index into entropy bytes
            let mut buf = [0; 2];
            ByteOrder_BigEndian::write_u16(&mut buf, index.unwrap() as u16);
            let mut index_bitvector = BitVec::<BigEndian>::from_bitslice(
                &BitVec::<BigEndian>::from_slice(&buf)[5..]);

            entropy.append(&mut index_bitvector);

        });
        let entropy_extracted: Vec<u8> = Vec::from(entropy[..entropy_length].as_slice());
        let mnemonic_extracted = Mnemonic::from_entropy(&entropy_extracted, language)?;

        return match phrase == mnemonic_extracted.phrase {
            true => Ok(entropy_extracted),
            false => Err(MnemonicError::InvalidPhrase(mnemonic_extracted.phrase))
        }
    }

    /// Returns position of word in word list if it exists
    fn get_wordlist_index(word: &str, language: &Language) -> Result<usize, MnemonicError> {
        let word_string = match language {
            Language::ENGLISH => fs::read_to_string("src/languages/english.txt").expect("Error reading file"),
            _ => panic!("Invalid language")
        };

        let index = word_string.lines().position(|x| x == word);

        return match index {
            Some(_) => Ok(index.unwrap()),
            None => Err(MnemonicError::InvalidWord(String::from(word)))
        }
    }

    /// Generates seed bytes from mnemonic
    pub fn to_seed(&self, password: Option<&str>) -> Result<Vec<u8>, MnemonicError> {
        let mut salt = String::from("mnemonic");
        let pass = password.unwrap_or_else(|| "");
//        match password {
//            Some(&str) => salt.push_str(password.unwrap()),
//            None => ()
//        };
        salt.push_str(pass);
//        println!("{:?}", &self.entropy);

        let mut seed = vec![0u8; PBKDF2_BYTES];
        pbkdf2::pbkdf2::<Hmac<Sha512>>(&self.entropy, salt.as_bytes(), PBKDF2_ROUNDS, &mut seed);

        Ok(seed)
    }

    /// returns whether or not mnemonic phrase is valid
    pub fn check_valid(phrase: &str, language: &Language) -> bool {
        match Mnemonic::to_entropy(phrase, language) {
            Ok(_) => true,
            Err(_) => false
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use hex;

    fn test_new(word_count: u8, language: &Language) {
        let result = Mnemonic::new(word_count, language).unwrap();
        test_from_entropy(&result.entropy, &result.phrase, &result.language);
    }

    fn test_from_entropy(entropy: &Vec<u8>, expected_phrase: &str, language: &Language) {
        let result = Mnemonic::from_entropy(&entropy, language).unwrap();
        assert_eq!(expected_phrase, result.phrase);
    }

    fn test_to_entropy(expected_entropy: &Vec<u8>, phrase: &str, language: &Language) {
        let result = Mnemonic::to_entropy(phrase, language).unwrap();
        assert_eq!(&expected_entropy[..], &result[..]);
    }

    fn test_from_phrase(expected_entropy: &Vec<u8>, phrase: &str, language: &Language) {
        let result = Mnemonic::from_phrase(phrase, language).unwrap();
        assert_eq!(&expected_entropy[..], &result.entropy[..]);
        assert_eq!(phrase, result.phrase);
//        assert_eq!(language, result.language);
    }

    fn test_check_valid(phrase: &str, language: &Language) {
        assert!(Mnemonic::check_valid(phrase, language));
    }

    mod english {
        use super::*;

        const PASSWORD: &str = "TREZOR";
        const LANGUAGE: &Language = &Language::ENGLISH;


        const KEYPAIRS: [(&str, &str, &str); 1] = [
            (
                "00000000000000000000000000000000",
                "abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about",
                "c55257c360c07c72029aebc1b53c05ed0362ada38ead3e3e9efa3708e53495531f09a6987599d18264c1e1c92f2cf141630c7a3c4ab7c81b2f001698e7463b04"
            )
        ];

        #[test]
        fn new() {
            let word_counts: [u8; 5] = [12, 15, 18, 21, 24];
            word_counts.iter().for_each(|word_count| {
                test_new(*word_count, LANGUAGE);
            })
        }

        #[test]
        fn from_entropy() {
            KEYPAIRS.iter().for_each(|(entropy_str, phrase, _)| {
                let entropy: Vec<u8> = Vec::from(hex::decode(entropy_str).unwrap());
                test_from_entropy(&entropy, phrase, LANGUAGE);
            });
        }


        #[test]
        fn to_entropy() {
            KEYPAIRS.iter().for_each(|(entropy_str, phrase, _)| {
                let entropy: Vec<u8> = Vec::from(hex::decode(entropy_str).unwrap());
                test_to_entropy(&entropy, phrase, LANGUAGE);
            })
        }

        #[test]
        fn from_phrase() {
            KEYPAIRS.iter().for_each(|(entropy_str, phrase, _)| {
                let entropy: Vec<u8> = Vec::from(hex::decode(entropy_str).unwrap());
                test_from_phrase(&entropy, phrase, LANGUAGE);
            })
        }


        #[test]
        fn to_seed() {
            KEYPAIRS.iter().for_each(|(entropy_str, _, expected_seed)| {
                let entropy: Vec<u8> = Vec::from(hex::decode(entropy_str).unwrap());
                let result = Mnemonic::from_entropy(&entropy, LANGUAGE).unwrap();
//                println!("{:?}", hex::encode(result.to_seed(None)));
//                println!("{:?}", hex::encode(result.to_seed(Some(PASSWORD))));
//                assert_eq!(expected_seed, &hex::encode(result.to_seed(Some(PASSWORD))))
            });
        }

        #[test]
        fn check_valid() {
            KEYPAIRS.iter().for_each(|(_, phrase, _)| {
                test_check_valid(phrase, LANGUAGE);
            });
        }
    }
}